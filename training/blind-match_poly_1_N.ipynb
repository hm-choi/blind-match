{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations on [BlindAuth] file import!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from imgaug import augmenters as iaa\n",
    "import torchvision\n",
    "import PIL.Image as Image\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "from blindMatch import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FingerprintDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, meta, degree, size=224):\n",
    "        with open(meta, 'r') as fin:\n",
    "            self.x = [x for x in fin]\n",
    "\n",
    "        self.transform = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize((size, size)),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.RandomRotation(degree),\n",
    "            torchvision.transforms.Normalize((0.5, 0.5, 0.5), (1.0, 1.0, 1.0))\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.x[idx].split('|')\n",
    "        # Write down your data path\n",
    "        root = '../data/PolyU_Dataset/'\n",
    "\n",
    "        file = Image.fromarray(cv2.imread(root + entry[0]))\n",
    "        file = self.transform(file)\n",
    "\n",
    "        n_id = entry[1]\n",
    "\n",
    "        return file, np.array(n_id, dtype=np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 512\n",
    "train_data = 'center_p'\n",
    "\n",
    "trainset = FingerprintDataset('../dataset/Poly/polyu_meta.txt', 0)\n",
    "testset = FingerprintDataset('../dataset/Poly/polyu_meta_eval.txt', 0)\n",
    "\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(trainset, batch_size=batch, shuffle=True, drop_last=True, num_workers=5)\n",
    "dataloader_val = torch.utils.data.DataLoader(testset, batch_size=batch, shuffle=False, drop_last=False, num_workers=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature size 128 STNet\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "c = 8\n",
    "num_ids = 400\n",
    "device = 'cuda'\n",
    "\n",
    "# network selecting - ST/Resnet18\n",
    "net = FingerSTNNet(16*c) # net = FingerNet(16*c)\n",
    "net = net.to(device)\n",
    "print(\"Feature size\", 16*c, \"STNet\")\n",
    "\n",
    "fc = FingerCentroids(num_ids, 16*c)\n",
    "fc = fc.to(device)\n",
    "\n",
    "\n",
    "loss_arcface = ArcFace(m=0.2)\n",
    "\n",
    "optim = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "degree = 20\n",
    "best_acc = 0\n",
    "best_loss = 100\n",
    "    \n",
    "\n",
    "\n",
    "for epoch in range(100):\n",
    "    net = net.train()\n",
    "    loss_accum = []\n",
    "\n",
    "    for idx, (img, lbl) in enumerate(dataloader):\n",
    "        img = img.to(device)\n",
    "        lbl = lbl.to(device)\n",
    "\n",
    "        feat = net(img)\n",
    "        logit = fc(feat)\n",
    "        logit = loss_arcface(logit, lbl)\n",
    "        \n",
    "        loss = torch.nn.functional.cross_entropy(logit, lbl)\n",
    "        loss_accum.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        if idx % 2 == 0:\n",
    "            print('.', end='')\n",
    "\n",
    "    loss_accum = torch.tensor(loss_accum)\n",
    "    print(f'epoch: {epoch} | loss: {loss_accum.mean().item():.04f}')\n",
    "\n",
    "    net = net.eval()\n",
    "    \n",
    "    eval_results = []\n",
    "    lbls = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (img, lbl) in enumerate(dataloader_val):\n",
    "            img = img.to(device)\n",
    "            feat = net(img)\n",
    "         \n",
    "            eval_results.append(feat.to('cpu'))\n",
    "            lbls.append(lbl)\n",
    "           \n",
    "\n",
    "        eval_results = torch.cat(eval_results)\n",
    "        mat_similarity = eval_results.matmul(eval_results.T)\n",
    "\n",
    "        lbls = torch.cat(lbls)\n",
    "        lbls = lbls.view(-1, lbls.size(0)) == lbls.view(lbls.size(0), -1)\n",
    "\n",
    "        accuracy = []\n",
    "\n",
    "        total_comp = torch.ones_like(mat_similarity).triu(1)\n",
    "        total_comp = total_comp.sum().item()\n",
    "\n",
    "        thresh_best_acc = 0\n",
    "        for threshold in [0.0, 0.2, 0.4, 0.5, 0.6, 0.7, 0,8, 0.85, 0.9, 0.95]:\n",
    "            threshed = mat_similarity > threshold\n",
    "            \n",
    "            #remove diagonal\n",
    "            correct = (threshed == lbls).triu(1).sum()\n",
    "\n",
    "            accuracy.append(correct / total_comp)\n",
    "            if accuracy[-1] > thresh_best_acc:\n",
    "                thresh_best_acc = accuracy[-1]\n",
    "        \n",
    "        print(f'Accuracy: {\" | \".join(f\"{acc:.03f}\" for acc in accuracy)}')\n",
    "        \n",
    "        if best_acc < thresh_best_acc:\n",
    "            best_acc = thresh_best_acc\n",
    "            best_loss = loss_accum.mean()\n",
    "            best_epoch = epoch\n",
    "            best_sim = mat_similarity\n",
    "            \n",
    "\n",
    "    print('=' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MOST\", best_loss, best_acc, best_epoch)\n",
    "\n",
    "accuracy = []\n",
    "for threshold in [0.0, 0.2, 0.4, 0.5, 0.6, 0.7, 0,8, 0.85, 0.9, 0.95]:\n",
    "    # threshed = best_sim > threshold8\n",
    "    threshed = best_sim > threshold\n",
    "    \n",
    "    #remove diagonal\n",
    "    correct = (threshed == lbls).triu(1).sum()\n",
    "\n",
    "    accuracy.append(correct / total_comp)\n",
    "    if accuracy[-1] > thresh_best_acc:\n",
    "        thresh_best_acc = accuracy[-1]\n",
    "        \n",
    "print(\"MOST\", best_loss, best_acc, thresh_best_acc)\n",
    "print(f'Accuracy: {\" | \".join(f\"{acc:.05f}\" for acc in accuracy) } \\n Loss: {\"\".join(f\"{loss_accum.mean():.05f}\")}')\n",
    "print(\"\".join(f\"{accuracy[-1]:.05f}\"), \"\".join(f\"{loss_accum[-1]:.05f}\"))\n",
    "print( 16*c, net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intern2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
